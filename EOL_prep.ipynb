{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['FileName', 'ClassId'])\n",
    "count=0\n",
    "for root, dirs, files in os.walk('/data/data'):\n",
    "    for name in files:\n",
    "        if name.endswith(\".jpg\"):\n",
    "            ClassId = root.replace('/data/data/','')\n",
    "            FileName = root + '/' + name\n",
    "            df.loc[count] = [FileName, ClassId]\n",
    "            count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "(256287, 2)\n",
      "(253321, 2)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import heapq\n",
    "import collections\n",
    "def least_common_values(array, to_find=None):\n",
    "    counter = collections.Counter(array)\n",
    "    if to_find is None:\n",
    "        return sorted(counter.items(), key=itemgetter(1), reverse=False)\n",
    "    return heapq.nsmallest(to_find, counter.items(), key=itemgetter(1))\n",
    "\n",
    "print(len(Counter(df.ClassId)))\n",
    "class_count = Counter(df.ClassId)\n",
    "new_count = {k:v for (k,v) in class_count.items() if v > 4}\n",
    "filtered_df = df.loc[df['ClassId'].isin(new_count.keys())]\n",
    "print(df.shape)\n",
    "print(filtered_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141859, 2)\n",
      "(60797, 2)\n",
      "(50665, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_df, filtered_df['ClassId'],\n",
    "                                                    stratify=filtered_df['ClassId'],\n",
    "                                                    random_state=123,\n",
    "                                                    test_size=0.2)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, X_train['ClassId'],\n",
    "                                                    stratify=X_train['ClassId'],\n",
    "                                                    random_state=123,\n",
    "                                                    test_size=0.3)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>FinalDir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/data/175562/261507.jpg</td>\n",
       "      <td>175562</td>\n",
       "      <td>/data/EOL_split/Training/175562/261507.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/data/53217/359087.jpg</td>\n",
       "      <td>53217</td>\n",
       "      <td>/data/EOL_split/Training/53217/359087.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/data/288713/325694.jpg</td>\n",
       "      <td>288713</td>\n",
       "      <td>/data/EOL_split/Training/288713/325694.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/data/252021/301415.jpg</td>\n",
       "      <td>252021</td>\n",
       "      <td>/data/EOL_split/Training/252021/301415.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/data/312660/179837.jpg</td>\n",
       "      <td>312660</td>\n",
       "      <td>/data/EOL_split/Training/312660/179837.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/data/data/270573/297181.jpg</td>\n",
       "      <td>270573</td>\n",
       "      <td>/data/EOL_split/Training/270573/297181.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/data/data/247391/333118.jpg</td>\n",
       "      <td>247391</td>\n",
       "      <td>/data/EOL_split/Training/247391/333118.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/data/data/315150/374306.jpg</td>\n",
       "      <td>315150</td>\n",
       "      <td>/data/EOL_split/Training/315150/374306.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/data/data/29663/284541.jpg</td>\n",
       "      <td>29663</td>\n",
       "      <td>/data/EOL_split/Training/29663/284541.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/data/data/118420/204466.jpg</td>\n",
       "      <td>118420</td>\n",
       "      <td>/data/EOL_split/Training/118420/204466.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       FileName  ClassId  \\\n",
       "0  /data/data/175562/261507.jpg   175562   \n",
       "1   /data/data/53217/359087.jpg    53217   \n",
       "2  /data/data/288713/325694.jpg   288713   \n",
       "3  /data/data/252021/301415.jpg   252021   \n",
       "4  /data/data/312660/179837.jpg   312660   \n",
       "5  /data/data/270573/297181.jpg   270573   \n",
       "6  /data/data/247391/333118.jpg   247391   \n",
       "7  /data/data/315150/374306.jpg   315150   \n",
       "8   /data/data/29663/284541.jpg    29663   \n",
       "9  /data/data/118420/204466.jpg   118420   \n",
       "\n",
       "                                     FinalDir  \n",
       "0  /data/EOL_split/Training/175562/261507.jpg  \n",
       "1   /data/EOL_split/Training/53217/359087.jpg  \n",
       "2  /data/EOL_split/Training/288713/325694.jpg  \n",
       "3  /data/EOL_split/Training/252021/301415.jpg  \n",
       "4  /data/EOL_split/Training/312660/179837.jpg  \n",
       "5  /data/EOL_split/Training/270573/297181.jpg  \n",
       "6  /data/EOL_split/Training/247391/333118.jpg  \n",
       "7  /data/EOL_split/Training/315150/374306.jpg  \n",
       "8   /data/EOL_split/Training/29663/284541.jpg  \n",
       "9  /data/EOL_split/Training/118420/204466.jpg  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "X_train = pd.read_csv(\"/data/EOL_split/training.csv\")\n",
    "X_validation = pd.read_csv(\"/data/EOL_split/validation.csv\")\n",
    "X_test = pd.read_csv(\"/data/EOL_split/test.csv\")\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "FinalDir = []\n",
    "for index, row in X_train.iterrows():\n",
    "    file_path = row['FileName']\n",
    "    target_dir = file_path.replace('/data/data/','/data/EOL_split/Training/')\n",
    "    FinalDir.append(target_dir)\n",
    "    if not os.path.exists(os.path.dirname(target_dir)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(target_dir))\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    try:\n",
    "        copyfile(file_path, target_dir)\n",
    "    except:\n",
    "        next\n",
    "X_train = X_train.assign(FinalDir=pd.Series(FinalDir).values)\n",
    "\n",
    "FinalDir = []\n",
    "for index, row in X_validation.iterrows():\n",
    "    file_path = row['FileName']\n",
    "    target_dir = file_path.replace('/data/data/','/data/EOL_split/Validation/')\n",
    "    FinalDir.append(target_dir)\n",
    "    if not os.path.exists(os.path.dirname(target_dir)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(target_dir))\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    try:\n",
    "        copyfile(file_path, target_dir)\n",
    "    except:\n",
    "        next\n",
    "X_validation = X_validation.assign(FinalDir=pd.Series(FinalDir).values)\n",
    "\n",
    "FinalDir = []\n",
    "for index, row in X_test.iterrows():\n",
    "    file_path = row['FileName']\n",
    "    target_dir = file_path.replace('/data/data/','/data/EOL_split/Test/')\n",
    "    FinalDir.append(target_dir)\n",
    "    if not os.path.exists(os.path.dirname(target_dir)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(target_dir))\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    try:\n",
    "        copyfile(file_path, target_dir)\n",
    "    except:\n",
    "        next\n",
    "X_test = X_test.assign(FinalDir=pd.Series(FinalDir).values)\n",
    "\n",
    "X_train.to_csv(\"/data/EOL_split/training.csv\",index=False)\n",
    "X_validation.to_csv(\"/data/EOL_split/validation.csv\",index=False)\n",
    "X_test.to_csv(\"/data/EOL_split/test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed: /data/EOL_split/Validation/37156/380797.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk('/data/EOL_split/Training'):\n",
    "    for name in files:\n",
    "        try:\n",
    "            Image.open(root + '/' + name)\n",
    "        except IOError:\n",
    "            os.remove(root + '/' + name)\n",
    "            print('removed: ' + root + '/' + name)\n",
    "\n",
    "for root, dirs, files in os.walk('/data/EOL_split/Validation'):\n",
    "    for name in files:\n",
    "        try:\n",
    "            Image.open(root + '/' + name)\n",
    "        except IOError:\n",
    "            os.remove(root + '/' + name)\n",
    "            print('removed: ' + root + '/' + name)\n",
    "\n",
    "for root, dirs, files in os.walk('/data/EOL_split/Test'):\n",
    "    for name in files:\n",
    "        try:\n",
    "            Image.open(root + '/' + name)\n",
    "        except IOError:\n",
    "            os.remove(root + '/' + name)\n",
    "            print('removed: ' + root + '/' + name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
